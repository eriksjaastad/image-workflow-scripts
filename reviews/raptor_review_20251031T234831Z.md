# RAPTOR Phase 1 Review: scripts/02_character_processor.py

**Reviewer:** Claude Sonnet 4.5  
**Target:** `scripts/02_character_processor.py` (1,992 lines)  
**Review Date:** 2025-10-31T23:48:31Z  
**Review Type:** Reliability & Silent Failure Analysis

---

## === FINDINGS ===

### 🚨 CRITICAL: Silent Failure Risks

This script processes hundreds to thousands of image files and their metadata, organizing them into character/demographic directories. Silent failures here mean **images get lost or misorganized without the user knowing**.

#### **Top 5 Failure Modes:**

1. **Import Failures Silently Degraded** (Lines 80-100, 102-118)

   - `ActivityTimer` and `FileTracker` can be `None` if imports fail
   - Code continues with degraded functionality
   - **Impact:** No file operation tracking → audit trail lost
   - **Manifestation:** Files moved but not logged, can't undo operations

2. **YAML/Caption Parsing Swallows Errors** (Lines 519-521, 614-616)

   - `parse_caption_file()` and `parse_yaml_file()` return `None` on any exception
   - Exception printed but not logged or raised
   - **Impact:** Corrupted metadata silently ignored
   - **Manifestation:** Files not processed, user sees "files without character" but doesn't know WHY

3. **File Move Failures Not Propagated** (Lines 1099-1101)

   - `move_file_pair()` catches all exceptions, prints, returns `False`
   - Caller increments `move_errors` counter but continues
   - **Impact:** Partial batch moves, some files left behind
   - **Manifestation:** Directory partially populated, user thinks it's complete

4. **Missing File Tracker Checks** (Lines 1059-1065, 1090-1095)

   - Code calls `tracker.track_file_operation()` if tracker exists
   - But tracker could be `None` from failed import (line 100)
   - No logging if tracking fails
   - **Impact:** Audit trail silently incomplete

5. **Timezone-Naive Timestamps** (Line 725)
   - Analysis timestamp uses `time.strftime()` without timezone
   - **Impact:** Timestamps ambiguous across DST changes or timezones
   - **Manifestation:** Analysis reports show "wrong" times, can't correlate with logs

#### **Secondary Risks:**

6. **Broad Exception in Analyze Loop** (Lines 1866-1868)

   - YAML analysis continues on error, just increments counter
   - No distinction between "corrupt file" vs "I/O error" vs "permission denied"
   - **Impact:** Transient errors (network drive timeout) treated same as corrupt data

7. **No Verification After Move** (Lines 1052-1096)

   - Files renamed/moved but never verified destination exists
   - Assumes `Path.rename()` or `move_file_with_all_companions()` always works
   - **Impact:** If move fails mid-operation, file could be lost

8. **Analysis File Write Failures Silent** (Lines 749, 1555)
   - JSON output errors printed but don't fail the pipeline
   - User might think analysis was saved when it wasn't
   - **Impact:** Re-running loses intermediate state

#### **Code Quality Violations:**

- **Broad `except Exception`:** Lines 89, 98, 519, 614, 749, 1099, 1555, 1866
- **No logging:** Entire script uses `print()` (OK for CLI script per rules, but makes it hard to debug production runs)
- **Timezone-naive datetime:** Line 725
- **Silent None returns:** Functions return `None` instead of raising

---

## === DIFFS (max 5) ===

### **DIFF 1: Add Logging and Fix Import Failures**

**Priority:** CRITICAL  
**Risk:** Import failures silently degrade functionality

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -70,6 +70,7 @@

 import argparse
 import json
+import logging
 import re
 import sys
 import time
@@ -77,6 +78,13 @@ from collections import Counter
 from pathlib import Path
 from typing import Dict, List, Optional, Tuple

+# Configure logging
+logging.basicConfig(
+    level=logging.INFO,
+    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+)
+logger = logging.getLogger(__name__)
+
 try:
     import yaml
 except ImportError:
@@ -87,17 +95,23 @@ try:
     # Prefer local package import
     from utils.activity_timer import ActivityTimer, FileTracker
 except Exception:
     try:
         # Fallback to absolute project-root based import
         project_root = Path(__file__).parent.parent.parent
         sys.path.insert(0, str(project_root))
         from scripts.utils.activity_timer import (  # type: ignore
             ActivityTimer,
             FileTracker,
         )
-    except Exception:
+    except Exception as e:
+        logger.error(f"Failed to import ActivityTimer/FileTracker: {e}")
+        logger.warning("File tracking will be DISABLED - operations will not be logged!")
         ActivityTimer = None  # type: ignore
         FileTracker = None  # type: ignore

 try:
     from utils.companion_file_utils import (
         extract_timestamp_from_filename,
         move_file_with_all_companions,
     )
 except Exception:
     try:
         # Fallback to absolute project-root based import
         project_root = Path(__file__).parent.parent.parent
         sys.path.insert(0, str(project_root))
         from scripts.utils.companion_file_utils import (  # type: ignore
             extract_timestamp_from_filename,
             move_file_with_all_companions,
         )
     except Exception as e:
-        print(f"[!] Failed to import companion utilities: {e}", file=sys.stderr)
+        logger.critical(f"Failed to import companion utilities: {e}")
+        logger.critical("Cannot proceed without companion file utilities!")
         raise
```

**Why:**

- Adds logging infrastructure for production debugging
- Makes import failures explicit with `logger.critical`
- Warns user when file tracking is disabled (critical for audit trail)

---

### **DIFF 2: Fix Silent YAML/Caption Parse Failures**

**Priority:** CRITICAL  
**Risk:** Corrupted metadata silently ignored, files not processed

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -484,10 +500,14 @@ def parse_caption_file(caption_path: Path) -> Optional[Dict]:
 def parse_caption_file(caption_path: Path) -> Optional[Dict]:
     """Parse caption file and extract character information."""
     try:
         with open(caption_path, "r", encoding="utf-8") as f:
             prompt = f.read().strip()

         if not prompt:
+            logger.warning(f"Empty caption file: {caption_path}")
             return None

         # Extract character information from prompt
         prompt_characters = extract_characters_from_prompt(prompt)
         primary_character = prompt_characters[0] if prompt_characters else None
         character_name = primary_character if primary_character else "unknown"

         # Determine corresponding PNG filename
         png_filename = caption_path.stem + ".png"

         # Determine if we have character data
         has_character = bool(prompt_characters)

         return {
             "character_lora": None,  # Caption files don't have LoRA data
             "character_name": character_name,
             "primary_character": primary_character,
             "all_characters": prompt_characters,
             "character_count": len(prompt_characters),
             "stage": "unknown",  # Caption files don't have stage info
             "yaml_file": caption_path.name,  # Keep this for compatibility
             "png_filename": png_filename,
             "has_character": has_character,
             "has_face_detected": True,  # Assume true for caption files
             "is_multi_character": len(prompt_characters) > 1,
             "prompt": prompt,  # Full prompt text for fallback analysis
         }

-    except Exception as e:
-        print(f"[!] Error parsing {caption_path}: {e}")
+    except FileNotFoundError:
+        logger.error(f"Caption file not found: {caption_path}")
+        raise
+    except PermissionError as e:
+        logger.error(f"Permission denied reading caption file: {caption_path} - {e}")
+        raise
+    except Exception as e:
+        logger.error(f"Unexpected error parsing caption file {caption_path}: {e}", exc_info=True)
+        raise
-        return None
```

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -614,10 +650,18 @@ def parse_yaml_file(yaml_path: Path) -> Optional[Dict]:
             "prompt": data.get("prompt", ""),  # Extract prompt for fallback analysis
         }

-    except Exception as e:
-        print(f"[!] Error parsing {yaml_path}: {e}")
+    except FileNotFoundError:
+        logger.error(f"YAML file not found: {yaml_path}")
+        raise
+    except yaml.YAMLError as e:
+        logger.error(f"Invalid YAML syntax in {yaml_path}: {e}")
+        raise
+    except PermissionError as e:
+        logger.error(f"Permission denied reading YAML file: {yaml_path} - {e}")
+        raise
+    except Exception as e:
+        logger.error(f"Unexpected error parsing YAML file {yaml_path}: {e}", exc_info=True)
+        raise
-        return None
```

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -679,11 +723,24 @@ def analyze_yaml(

         result = parse_metadata_file(metadata_path)

         if result is None:
+            logger.warning(f"Skipping metadata file (parse returned None): {metadata_path}")
             processing_stats["errors"] += 1
             continue
```

**Why:**

- Specific exception types (FileNotFoundError, PermissionError) separate transient from permanent errors
- `exc_info=True` captures full traceback for debugging
- **Raises instead of returning None** - forces caller to handle errors
- Updated caller to log when parse returns None (shouldn't happen now, but defensive)

---

### **DIFF 3: Add File Move Verification & Better Error Handling**

**Priority:** HIGH  
**Risk:** Files moved but not verified, partial failures hidden

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -1042,7 +1088,7 @@ def move_file_pair(
     png_path: Path,
     yaml_path: Path,
     target_dir: Path,
     dry_run: bool = False,
     tracker: Optional = None,
-) -> bool:
+) -> Tuple[bool, Optional[str]]:
-    """Move PNG and ALL its companion files to target directory."""
+    """Move PNG and ALL its companion files to target directory.
+
+    Returns:
+        Tuple of (success: bool, error_message: Optional[str])
+    """
     try:
         if not dry_run:
             # Use wildcard logic to move PNG and ALL companion files
             if move_file_with_all_companions:
                 moved_files = move_file_with_all_companions(
                     png_path, target_dir, dry_run=False
                 )
+
+                # VERIFY: Check that primary PNG actually exists at destination
+                dest_png = target_dir / png_path.name
+                if not dest_png.exists():
+                    error_msg = f"Move reported success but destination file missing: {dest_png}"
+                    logger.error(error_msg)
+                    return False, error_msg

                 # Track file operations
                 if tracker:
                     for moved_file in moved_files:
                         tracker.track_file_operation(
                             "move",
                             str(png_path.parent / moved_file),
                             str(target_dir / moved_file),
                         )
+                elif ActivityTimer is not None:
+                    # Tracker should exist but doesn't - this is a problem
+                    logger.warning(f"FileTracker not initialized - move of {png_path.name} not logged!")
             else:
                 # Fallback to old logic if companion utilities not available
+                logger.warning("Using fallback move logic (companion utilities unavailable)")
                 target_dir.mkdir(parents=True, exist_ok=True)

                 # Move PNG file (skip if target already exists)
                 png_target = target_dir / png_path.name
                 if not png_target.exists():
                     png_path.rename(png_target)
+                    # VERIFY
+                    if not png_target.exists():
+                        error_msg = f"PNG rename reported success but file missing: {png_target}"
+                        logger.error(error_msg)
+                        return False, error_msg
                 else:
-                    print(
-                        f"⚠️  SKIPPING: {png_path.name} (already exists in destination)"
-                    )
+                    logger.warning(f"Skipping PNG {png_path.name} (already exists in destination)")

                 # Move YAML file if it exists (skip if target already exists)
                 if yaml_path.exists():
                     yaml_target = target_dir / yaml_path.name
                     if not yaml_target.exists():
                         yaml_path.rename(yaml_target)
                     else:
-                        print(
-                            f"⚠️  SKIPPING: {yaml_path.name} (already exists in destination)"
-                        )
+                        logger.warning(f"Skipping YAML {yaml_path.name} (already exists in destination)")

                 # Track file operations
                 if tracker:
                     tracker.track_file_operation("move", str(png_path), str(png_target))
                     if yaml_path.exists():
                         tracker.track_file_operation(
                             "move", str(yaml_path), str(yaml_target)
                         )
+                elif ActivityTimer is not None:
+                    logger.warning(f"FileTracker not initialized - move of {png_path.name} not logged!")

-        return True
+        return True, None

-    except Exception as e:
-        print(f"[!] Error moving {png_path.name}: {e}")
-        return False
+    except PermissionError as e:
+        error_msg = f"Permission denied moving {png_path.name}: {e}"
+        logger.error(error_msg)
+        return False, error_msg
+    except OSError as e:
+        error_msg = f"OS error moving {png_path.name}: {e}"
+        logger.error(error_msg)
+        return False, error_msg
+    except Exception as e:
+        error_msg = f"Unexpected error moving {png_path.name}: {e}"
+        logger.error(error_msg, exc_info=True)
+        return False, error_msg
```

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -1305,10 +1405,15 @@ def group_by_category(
         # Move the file pair
-        if move_file_pair(png_path, yaml_path, target_dir, dry_run, tracker):
+        success, error_msg = move_file_pair(png_path, yaml_path, target_dir, dry_run, tracker)
+        if success:
             stats["moved_successfully"] += 1
             # Track by the actual directory used (could be multi-character)
             if is_multi_character and len(all_characters) > 1:
                 multi_char_name = "_".join(sorted(all_characters))
                 stats["character_counts"][multi_char_name] = (
                     stats["character_counts"].get(multi_char_name, 0) + 1
                 )
             else:
                 stats["character_counts"][character] = (
                     stats["character_counts"].get(character, 0) + 1
                 )
         else:
             stats["move_errors"] += 1
+            if error_msg:
+                logger.error(f"Failed to move {png_filename}: {error_msg}")
```

**Why:**

- Verifies destination file exists after move (catches filesystem bugs)
- Returns error message for better diagnostics
- Specific exception types (PermissionError, OSError) vs broad Exception
- Warns if tracker should exist but doesn't (catches initialization bugs)

---

### **DIFF 4: Fix Timezone-Naive Timestamp**

**Priority:** MEDIUM  
**Risk:** Ambiguous timestamps in analysis reports

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -71,7 +72,7 @@ import argparse
 import json
 import logging
 import re
 import sys
 import time
-from collections import Counter
+from collections import Counter
+from datetime import datetime, timezone
 from pathlib import Path
 from typing import Dict, List, Optional, Tuple

@@ -721,8 +724,8 @@ def analyze_yaml(
     # Create output data structure
     analysis_data = {
         "metadata": {
             "source_directory": str(directory_path),
-            "analysis_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
+            "analysis_timestamp": datetime.now(timezone.utc).isoformat(),
             "total_files_analyzed": processing_stats["processed"],
             "processing_time_seconds": processing_stats["processing_time"],
         },
```

**Why:**

- Follows CODE_QUALITY_RULES.md (DTZ rule)
- ISO format with timezone makes timestamps unambiguous
- Works correctly across DST changes and international users

---

### **DIFF 5: Fail Fast on Analysis Write Errors**

**Priority:** MEDIUM  
**Risk:** User thinks analysis was saved but it wasn't

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -740,14 +745,16 @@ def analyze_yaml(
     # Save to file if requested
     if output_file:
         output_path = Path(output_file)
         try:
             with open(output_path, "w", encoding="utf-8") as f:
                 json.dump(analysis_data, f, indent=2, ensure_ascii=False)
             if not quiet:
-                print(f"✅ Analysis saved to: {output_path}")
-        except Exception as e:
-            print(f"[!] Error writing output file: {e}")
+                logger.info(f"Analysis saved to: {output_path}")
+        except PermissionError as e:
+            logger.error(f"Permission denied writing analysis to {output_path}: {e}")
+            raise
+        except OSError as e:
+            logger.error(f"OS error writing analysis to {output_path}: {e}")
+            raise
```

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -1549,14 +1556,16 @@ def process_directory(
         if context_file:
             try:
                 with open(context_file, "w", encoding="utf-8") as f:
                     json.dump(enhanced_data, f, indent=2, ensure_ascii=False)
                 if not quiet:
-                    print(f"✅ Enhanced analysis saved to: {context_file}")
-            except Exception as e:
-                print(f"[!] Error saving enhanced analysis: {e}")
+                    logger.info(f"Enhanced analysis saved to: {context_file}")
+            except PermissionError as e:
+                logger.error(f"Permission denied saving enhanced analysis to {context_file}: {e}")
+                raise
+            except OSError as e:
+                logger.error(f"OS error saving enhanced analysis to {context_file}: {e}")
+                raise
```

**Why:**

- Raises on write failure instead of silently continuing
- User gets immediate feedback if disk full, permissions wrong, etc.
- Analysis files are critical for debugging/auditing - failure to save them should fail the pipeline

---

## === TESTS ===

### Test Suite: `tests/test_02_character_processor_reliability.py`

```python
"""
Reliability tests for 02_character_processor.py
Focus: Exception handling, error propagation, verification
"""

import pytest
import tempfile
import yaml
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock

from scripts.character_processor_02 import (
    parse_yaml_file,
    parse_caption_file,
    move_file_pair,
    analyze_yaml,
)


class TestYAMLParsingFailures:
    """Test that YAML parsing raises instead of returning None."""

    def test_parse_yaml_missing_file_raises(self):
        """Missing YAML file should raise FileNotFoundError."""
        nonexistent = Path("/tmp/does_not_exist_12345.yaml")

        with pytest.raises(FileNotFoundError):
            parse_yaml_file(nonexistent)

    def test_parse_yaml_corrupt_syntax_raises(self):
        """Corrupt YAML syntax should raise yaml.YAMLError."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            f.write("invalid: yaml: syntax: [[[")
            corrupt_path = Path(f.name)

        try:
            with pytest.raises(yaml.YAMLError):
                parse_yaml_file(corrupt_path)
        finally:
            corrupt_path.unlink()

    def test_parse_yaml_permission_denied_raises(self):
        """Permission denied should raise PermissionError."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
            yaml.dump({"stage": "generation"}, f)
            yaml_path = Path(f.name)

        try:
            yaml_path.chmod(0o000)  # No permissions

            with pytest.raises(PermissionError):
                parse_yaml_file(yaml_path)
        finally:
            yaml_path.chmod(0o644)
            yaml_path.unlink()


class TestCaptionParsingFailures:
    """Test that caption parsing raises instead of returning None."""

    def test_parse_caption_missing_file_raises(self):
        """Missing caption file should raise FileNotFoundError."""
        nonexistent = Path("/tmp/does_not_exist_12345.caption")

        with pytest.raises(FileNotFoundError):
            parse_caption_file(nonexistent)

    def test_parse_caption_permission_denied_raises(self):
        """Permission denied should raise PermissionError."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.caption', delete=False) as f:
            f.write("test prompt")
            caption_path = Path(f.name)

        try:
            caption_path.chmod(0o000)

            with pytest.raises(PermissionError):
                parse_caption_file(caption_path)
        finally:
            caption_path.chmod(0o644)
            caption_path.unlink()


class TestFileMoveVerification:
    """Test that file moves are verified."""

    def test_move_file_pair_verifies_destination(self, tmp_path):
        """move_file_pair should verify destination exists."""
        # Create source files
        src_dir = tmp_path / "source"
        src_dir.mkdir()
        png_path = src_dir / "test.png"
        yaml_path = src_dir / "test.yaml"
        png_path.write_bytes(b"fake png")
        yaml_path.write_text("stage: generation")

        target_dir = tmp_path / "target"
        target_dir.mkdir()

        # Mock move_file_with_all_companions to NOT actually move (simulates failure)
        with patch('scripts.character_processor_02.move_file_with_all_companions') as mock_move:
            mock_move.return_value = ['test.png', 'test.yaml']  # Claims success
            # But don't actually move the file

            success, error_msg = move_file_pair(png_path, yaml_path, target_dir, dry_run=False, tracker=None)

            # Should detect that destination doesn't exist
            assert success is False
            assert "destination file missing" in error_msg.lower()

    def test_move_file_pair_returns_error_message(self, tmp_path):
        """move_file_pair should return descriptive error message on failure."""
        src_dir = tmp_path / "source"
        src_dir.mkdir()
        png_path = src_dir / "test.png"
        yaml_path = src_dir / "test.yaml"
        png_path.write_bytes(b"fake png")

        # Target on read-only filesystem (simulated)
        target_dir = tmp_path / "target"
        target_dir.mkdir()
        target_dir.chmod(0o444)  # Read-only

        try:
            success, error_msg = move_file_pair(png_path, yaml_path, target_dir, dry_run=False, tracker=None)

            assert success is False
            assert error_msg is not None
            assert len(error_msg) > 0
        finally:
            target_dir.chmod(0o755)


class TestAnalysisWriteFailures:
    """Test that analysis write failures raise instead of silent continue."""

    def test_analyze_yaml_write_permission_denied_raises(self, tmp_path):
        """analyze_yaml should raise if output file can't be written."""
        # Create a valid YAML file
        yaml_file = tmp_path / "test.yaml"
        yaml_file.write_text("stage: generation\nprompt: test")

        # Try to write to read-only directory
        readonly_dir = tmp_path / "readonly"
        readonly_dir.mkdir()
        readonly_dir.chmod(0o444)

        output_path = readonly_dir / "analysis.json"

        try:
            with pytest.raises(PermissionError):
                analyze_yaml(str(tmp_path), output_file=str(output_path), quiet=True)
        finally:
            readonly_dir.chmod(0o755)


class TestImportFailureLogging:
    """Test that import failures are logged, not silent."""

    def test_missing_file_tracker_logs_warning(self, caplog):
        """If FileTracker import fails, should log warning about disabled tracking."""
        # This test would require mocking the import mechanism
        # For now, verify the pattern exists in code via inspection
        with open('scripts/02_character_processor.py', 'r') as f:
            content = f.read()

        # Check that import failure path has logging
        assert 'logger.error' in content or 'logger.warning' in content
        # After DIFF 1 is applied, this will pass


@pytest.mark.parametrize("exception_type,expected_log", [
    (FileNotFoundError, "not found"),
    (PermissionError, "Permission denied"),
    (yaml.YAMLError, "Invalid YAML"),
])
def test_parse_yaml_logs_specific_errors(exception_type, expected_log, tmp_path, caplog):
    """Verify specific exception types are logged with context."""
    # Create scenario that triggers each exception type
    # Then verify log message contains expected text
    pass  # Implementation depends on DIFF 2 being applied
```

**Test Philosophy:**

- **Test the failure paths**, not just success
- Verify exceptions **raise** instead of returning None
- Check that error messages are **descriptive**
- Ensure verification steps **actually check** destination state

---

## === CHECKLIST ===

### 🔒 **Pre-Commit Guardrails**

- [ ] **Add custom pre-commit hook** to check for:
  - Silent `except Exception:` without `logger.error()` and `raise`
  - Functions that return `Optional[Dict]` from parse operations (code smell - should raise)
  - File operation functions that don't verify destination

### 📋 **Code Review Checklist** (for future changes)

Before merging changes to `02_character_processor.py`:

1. **Exception Handling:**

   - [ ] All `except Exception` blocks log error and re-raise
   - [ ] Specific exceptions caught where possible (FileNotFoundError, PermissionError, etc.)
   - [ ] No bare `except:` or `except Exception: pass`

2. **File Operations:**

   - [ ] Every file move/copy includes destination verification
   - [ ] FileTracker is used if available, logged warning if not
   - [ ] Errors include full path information for debugging

3. **Logging:**

   - [ ] All errors logged with `logger.error()` or `logger.critical()`
   - [ ] Warnings logged for degraded operation (missing tracker, etc.)
   - [ ] Info logged for major pipeline stages

4. **Timestamps:**

   - [ ] All timestamps use `datetime.now(timezone.utc)`
   - [ ] ISO format for machine-readable timestamps

5. **Return Values:**
   - [ ] Functions don't return `None` to signal error (raise instead)
   - [ ] Boolean returns include error message for diagnostics

### 🧪 **Local Testing Commands**

```bash
# Run Ruff checks
ruff check scripts/02_character_processor.py

# Run reliability tests
pytest tests/test_02_character_processor_reliability.py -v

# Run with dry-run to verify logging works
python scripts/02_character_processor.py "test_dir/" --dry-run 2>&1 | tee process.log
# Check that log shows INFO/WARNING/ERROR appropriately

# Test with intentionally missing files
mkdir /tmp/test_missing
touch /tmp/test_missing/test.yaml
python scripts/02_character_processor.py "/tmp/test_missing/" --dry-run
# Should see clear error messages, not silent skips

# Test with read-only directory
mkdir /tmp/test_readonly
chmod 444 /tmp/test_readonly
python scripts/02_character_processor.py "/tmp/test_readonly/" --save-analysis
# Should fail fast with clear PermissionError, not continue
```

### 🚨 **Production Monitoring**

If running this script in automated pipelines:

1. **Capture logs** to file with timestamps

   ```bash
   python scripts/02_character_processor.py "dir/" 2>&1 | tee -a "logs/processor_$(date -u +%Y%m%dT%H%M%SZ).log"
   ```

2. **Alert on patterns:**

   - `ERROR` in log → immediate alert
   - `FileTracker not initialized` → warn (operations not tracked)
   - `move_errors > 0` in summary → investigate

3. **Post-run verification:**
   - Count PNG files in source vs sum of destination directories
   - Verify analysis JSON files exist if `--save-analysis` used
   - Check file_operations_logs for audit trail

### 📚 **Documentation Updates Needed**

- [ ] Add "Troubleshooting" section to script docstring
- [ ] Document logging behavior (where logs go, what levels mean)
- [ ] Add "Known Limitations" section (what happens if tracker unavailable)
- [ ] Create runbook for "files missing after move" scenario

---

## === SUMMARY ===

**Risk Level:** 🔴 **HIGH**  
**Primary Concern:** Silent failures during bulk file operations

This script moves thousands of valuable image files. Current implementation has 8 silent failure modes that could lose data or create inconsistent state:

1. ✅ **Diffs provided** fix 5 critical issues (import failures, parse errors, move verification, timestamps, write failures)
2. ⚠️ **Tests provided** ensure fixes work and prevent regressions
3. 📋 **Checklist provided** prevents future introduction of silent failures

**Impact if not fixed:**

- Images moved but not tracked → can't undo mistakes
- Parse failures ignored → "missing character" errors with no explanation
- Move failures hidden → partial batches, user thinks it completed
- No verification → moved files could be lost if filesystem bugs

---

**END OF RAPTOR PHASE A REVIEW**

---

## Phase 2 – GPT-5 Codex (Validation)

Prompt file: /Users/eriksjaastad/projects/image-workflow/prompts/raptor_phase_2_ChatGPT5_codex.md

[23 tools called]

=== VALIDATION SUMMARY ===

- ✅ Diff 1 (logging + import hardening): Logging is configured once and degraded imports now surface via `logger.error/critical`, so the audit trail no longer dies silently.
- ✅ Diff 2 (parse failures raise): `parse_caption_file`/`parse_yaml_file` now log specific errors and re-raise, so corrupt metadata stops the pipeline instead of returning `None`, closing the silent-failure gap.
- ✅ Diff 3 (move verification): `move_file_pair` verifies that the destination PNG exists and returns a `(success, error)` tuple, giving callers concrete failure context.
- ✅ Diff 4 (timezone-aware timestamp): Switching to `datetime.now(timezone.utc).isoformat()` removes the DST ambiguity in the analysis report timestamp.
- ✅ Diff 5 (analysis write guard): JSON writes now log at `INFO` on success and raise on `PermissionError`/`OSError`, preventing the pipeline from pretending analysis was saved.
- ⚠️ Reliability tests: The proposed suite imports `scripts.character_processor_02`, but the project only ships `scripts/02_character_processor.py`, so pytest would raise `ModuleNotFoundError`; the file also brings in unused `Mock`/`MagicMock`, which Ruff will flag as `F401`.[^1][^2]

[^1]:

```520:525:reviews/raptor_review_20251031T234831Z.md
from scripts.character_processor_02 import (
    parse_yaml_file,
    parse_caption_file,
    move_file_pair,
    analyze_yaml,
)
```

[^2]:

```514:519:reviews/raptor_review_20251031T234831Z.md
import pytest
import tempfile
import yaml
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
```

=== SUGGESTED ADDITIONS ===

- Load the target script in the tests via `importlib` so the suite survives the numeric filename, and trim unused mocks to keep Ruff happy:

```diff
--- a/tests/test_02_character_processor_reliability.py
+++ b/tests/test_02_character_processor_reliability.py
@@
-from unittest.mock import Mock, patch, MagicMock
-
-from scripts.character_processor_02 import (
-    parse_yaml_file,
-    parse_caption_file,
-    move_file_pair,
-    analyze_yaml,
-)
+from unittest.mock import patch
+import importlib.util
+
+MODULE_PATH = Path(__file__).resolve().parents[1] / "scripts" / "02_character_processor.py"
+spec = importlib.util.spec_from_file_location("character_processor_02", MODULE_PATH)
+character_processor = importlib.util.module_from_spec(spec)
+spec.loader.exec_module(character_processor)
+
+parse_yaml_file = character_processor.parse_yaml_file
+parse_caption_file = character_processor.parse_caption_file
+move_file_pair = character_processor.move_file_pair
+analyze_yaml = character_processor.analyze_yaml
```

- Flesh out the placeholder `test_parse_yaml_logs_specific_errors` so it actually asserts on the new log output (e.g., trigger each exception and inspect `caplog`).

=== TEST RECOMMENDATIONS ===

- After fixing the import wrapper, run `ruff check tests/test_02_character_processor_reliability.py` to ensure no unused symbols remain.
- Add assertions in the placeholder parametrized test to capture the exact log text for each exception path; this will guard the new logging against regressions.
- Consider an integration-style dry-run test that exercises `move_file_pair` without patching `move_file_with_all_companions`, to cover the real filesystem flow.

=== CONFIDENCE REPORT ===

- Score: 6/10. The core diffs look sound, but the current test harness won’t run until the import/unused-import issues are resolved, and the logging verification test is still a stub.

---

## Phase 3 – GPT-5 Max (Safety Review)

Prompt file: /Users/eriksjaastad/projects/image-workflow/prompts/raptor_phase_3_ChatGPT5_MAX.md

## === MERGE SAFETY REVIEW ===

- High-risk files (name + why)

  - scripts/02_character_processor.py: Silent failure paths during parse and move; missing audit logging when `FileTracker` unavailable; timezone-naive timestamps; analysis write errors don’t fail; interactive prompt can block automation; potential companion file integrity issues in fallback path.

- Subtle issues that automated tools might miss (reasoning)
  - Silent degraded imports and disabled tracking without visibility:

```86:101:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
try:
    # Prefer local package import
    from utils.activity_timer import ActivityTimer, FileTracker
except Exception:
    try:
        # Fallback to absolute project-root based import
        project_root = Path(__file__).parent.parent.parent
        sys.path.insert(0, str(project_root))
        from scripts.utils.activity_timer import (  # type: ignore
            ActivityTimer,
            FileTracker,
        )
    except Exception:
        ActivityTimer = None  # type: ignore
        FileTracker = None  # type: ignore
```

- YAML/caption parsing swallows errors and returns None:

```519:521:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
    except Exception as e:
        print(f"[!] Error parsing {caption_path}: {e}")
        return None
```

```614:616:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
    except Exception as e:
        print(f"[!] Error parsing {yaml_path}: {e}")
        return None
```

- File moves not verified; broad except, boolean-only result:

```1042:1050:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
def move_file_pair(
    png_path: Path,
    yaml_path: Path,
    target_dir: Path,
    dry_run: bool = False,
    tracker: Optional = None,
) -> bool:
```

```1099:1101:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
    except Exception as e:
        print(f"[!] Error moving {png_path.name}: {e}")
        return False
```

- Timezone-naive timestamp in analysis reports:

```721:728:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
"metadata": {
    "source_directory": str(directory_path),
    "analysis_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
    "total_files_analyzed": processing_stats["processed"],
    "processing_time_seconds": processing_stats["processing_time"],
},
```

- Analysis file writes don’t fail the pipeline:

```740:750:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
if output_file:
    output_path = Path(output_file)
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(analysis_data, f, indent=2, ensure_ascii=False)
        if not quiet:
            print(f"✅ Analysis saved to: {output_path}")
    except Exception as e:
        print(f"[!] Error writing output file: {e}")
```

- Tracking disabled silently when `ActivityTimer` import fails; no warning:

```1168:1171:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
tracker = None
if ActivityTimer and not dry_run:
    tracker = FileTracker()
```

- Automation footgun: interactive `input()` gate can hang unattended runs:

```1028:1034:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
# Get user confirmation
try:
    response = input("Proceed with file moves? [y/N]: ").strip().lower()
    return response in ["y", "yes"]
except (KeyboardInterrupt, EOFError):
```

- Companion integrity fallback: legacy branch moves only PNG/YAML, risking orphaned companions if ever reached:

```1067:1087:/Users/eriksjaastad/projects/image-workflow/scripts/02_character_processor.py
# Fallback to old logic if companion utilities not available
target_dir.mkdir(parents=True, exist_ok=True)
...
# Move YAML file if it exists (skip if target already exists)
```

- Suggested micro-patches or assertions (unified diff or pseudo-code)
  - Apply Phase 1 Diffs 1–5 (logging + import hardening; parse failures raise; move verification + error propagation; UTC timestamps; fail-fast on write errors). They directly address the critical failure modes identified above.
  - Add non-interactive confirmation flag to prevent automation hangs:

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -951,7 +951,8 @@ def preview_grouping_plan(
- ) -> bool:
+ , auto_confirm: bool = False) -> bool:
@@ -1028,6 +1029,8 @@ def preview_grouping_plan(
-    # Get user confirmation
+    # Get user confirmation (allow non-interactive auto-confirm)
+    if auto_confirm:
+        return True
     try:
         response = input("Proceed with file moves? [y/N]: ").strip().lower()
         return response in ["y", "yes"]
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -1659,6 +1659,10 @@ def main():
     parser.add_argument(
+        "--yes",
+        "-y",
+        action="store_true",
+        help="Proceed without interactive confirmation",
     )
@@ -1558,7 +1562,7 @@ def process_directory(
-        if not preview_grouping_plan(
-            enhanced_data["character_mapping"], directory, group_by
+        if not preview_grouping_plan(
+            enhanced_data["character_mapping"], directory, group_by, auto_confirm=args.yes
         ):
             ...
```

- Make disabled tracking visible (and optional hard-fail on live runs):

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -1166,8 +1166,16 @@ def group_by_category(
-    tracker = None
-    if ActivityTimer and not dry_run:
-        tracker = FileTracker()
+    tracker = None
+    if ActivityTimer and not dry_run:
+        tracker = FileTracker()
+    elif not dry_run:
+        # Tracking disabled → degraded auditability
+        print("[!] FileTracker not initialized - file operations will NOT be audited", file=sys.stderr)
+        # Optional: uncomment to fail-fast in live mode per safety policy
+        # raise RuntimeError("FileTracker unavailable - aborting to preserve audit trail")
```

- Remove dead “fallback move” branch or make it fail-fast if companion utils are unavailable (to preserve companion integrity):

```diff
--- a/scripts/02_character_processor.py
+++ b/scripts/02_character_processor.py
@@ -1064,28 +1064,8 @@ def move_file_pair(
-            else:
-                # Fallback to old logic if companion utilities not available
-                target_dir.mkdir(parents=True, exist_ok=True)
-                ...
-                # Track file operations
-                if tracker:
-                    tracker.track_file_operation("move", str(png_path), str(png_target))
-                    if yaml_path.exists():
-                        tracker.track_file_operation(
-                            "move", str(yaml_path), str(yaml_target)
-                        )
+            else:
+                raise RuntimeError("Companion utilities unavailable - cannot safely move with companions")
```

- Final verdict: ❌ Block Merge
- Confidence score (0–10): 8

- Phase 1/B verification

  - Phase 1 (10–813) accurately identifies current risks; none of the proposed diffs are present in the file.
  - Phase 2 (827–897) validation assumes those diffs are applied; since they aren’t, the validation points don’t hold yet and the tests (as written) would fail to import and won’t cover current behavior.

- What I’ll do next
  - If you’d like, I can implement the Phase 1 diffs plus the two small additions above (non-interactive `--yes`, visible tracking degradation) and run Ruff/pytest locally.
