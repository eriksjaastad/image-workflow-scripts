# AI Training Session Summary - October 20, 2025

## ğŸ¯ What We Accomplished Today

### âœ… Phase 2.3: Ranking Model Training (COMPLETE)
**Time:** ~30 minutes  
**Data:** 9,838 Mojo 2 selection decisions  
**Result:** 98.26% validation accuracy

**Key Findings:**
- âš ï¸ Model achieved high accuracy but learned a simple rule: "pick highest stage"
- âŒ Failed to detect anomalies (only 2.8% accuracy on 142 cases where Erik chose lower stage)
- ğŸ” Root cause: CLIP embeddings don't capture fine anatomical details (missing belly buttons, face artifacts)
- ğŸ“‹ Solution: Need more diverse training data from historical projects

**Files Created:**
- `scripts/ai/train_ranker.py` - Training script
- `scripts/ai/test_anomaly_detection.py` - Validation script
- `data/ai_data/models/ranker_v1.pt` - Trained model
- `data/ai_data/models/ranker_v1_metadata.json` - Model metadata

---

### â³ Phase 2.4: Crop Proposer Training (IN PROGRESS)
**Started:** Oct 20, 2:47 PM  
**Data:** 7,194 crop decisions (Mojo 1 + 2)  
**Status:** Training in background (~15-20 mins remaining)

**Configuration:**
- Input: 514-dim (512 CLIP embedding + 2 dimension features)
- Output: 4 normalized coordinates [x1, y1, x2, y2]
- Architecture: MLP (514 â†’ 512 â†’ 256 â†’ 128 â†’ 4)
- Loss: MSE (Mean Squared Error)
- Epochs: 50
- Split: 6,115 train / 1,079 validation

**Files Created:**
- `scripts/ai/train_crop_proposer.py` - Training script
- `data/ai_data/models/crop_proposer_v1.pt` - Model (being saved)
- `data/ai_data/models/crop_proposer_v1_metadata.json` - Metadata (being saved)

---

### ğŸ“Š Phase 2.2.1: Feature Extraction (COMPLETE)
**Completed:** Earlier today, 19 minutes  
**Processed:** 17,934 out of 17,935 Mojo 2 images  
**Result:** CLIP embeddings cached

**Files Created:**
- `scripts/ai/compute_embeddings.py` - Extraction script
- `data/ai_data/cache/processed_images.jsonl` - Metadata cache
- `data/ai_data/cache/embeddings/*.npy` - 17,934 embedding files

---

### ğŸ“‹ Documentation & Planning (COMPLETE)

**Historical Data Extraction Plan:**
- `Documents/AI_HISTORICAL_DATA_EXTRACTION_PLAN.md` - Detailed extraction strategy
- `Documents/AI_TRAINING_FROM_PAST_PROJECTS.md` - Overview and approach
- Strategy: Compare original vs final directories to extract (winner, losers) pairs
- Expected yield: ~23,000 selection decisions, ~700-800 anomaly cases

**Updates:**
- `Documents/AI_PROJECT_IMPLEMENTATION_PLAN.md` - Updated with Phase 2.3 & 2.4 status
- TODO list maintained throughout session

---

## ğŸ¯ Next Steps (For New Session)

### Immediate (While Crop Training Completes):
1. âœ… Check crop proposer training results
2. âœ… Validate crop proposer model performance
3. âœ… Clean up sandbox/ directory (~86 GB to free)
   - Delete `sandbox/mojo2/` (76 GB)
   - Delete `sandbox/mojo2_challenge/` (5.1 GB)
   - Delete `sandbox/mojo2_subset/` (5.2 GB)

### Mojo 1 Training Data:
4. ğŸ“¥ Download Mojo 1 original + final directories
5. ğŸ”„ Build extraction script: `scripts/ai/extract_historical_training.py`
6. ğŸ“Š Extract training data from Mojo 1 (original vs final comparison)
7. ğŸ§  Extract CLIP embeddings from Mojo 1 images
8. ğŸ“ Retrain ranking model on combined Mojo 1 + 2 data
9. ğŸ—‘ï¸ Archive/delete Mojo 1 directories after embedding extraction

### Other Historical Projects:
10. ğŸ“‹ Inventory which historical projects have original + final archives
11. ğŸ”„ Extract training data from all available projects
12. ğŸ“ Retrain with full dataset (~23K examples)

### Integration:
13. ğŸ› ï¸ Integrate trained models into `scripts/01_ai_assisted_reviewer.py`
14. ğŸ§ª Test AI reviewer tool in sandbox
15. ğŸ“Š Collect feedback and iterate

---

## ğŸ“ Key Files & Locations

### Models
```
data/ai_data/models/
â”œâ”€â”€ ranker_v1.pt                        # Ranking model (needs retraining)
â”œâ”€â”€ ranker_v1_metadata.json
â”œâ”€â”€ crop_proposer_v1.pt                 # Crop model (training in progress)
â””â”€â”€ crop_proposer_v1_metadata.json
```

### Training Data
```
data/training/
â”œâ”€â”€ selection_only_log.csv              # 9,838 selection decisions
â”œâ”€â”€ select_crop_log.csv                 # 7,194 crop decisions
â””â”€â”€ (future) historical_projects.jsonl  # To be extracted
```

### Embeddings Cache
```
data/ai_data/cache/
â”œâ”€â”€ processed_images.jsonl              # Metadata for 17,934 images
â””â”€â”€ embeddings/*.npy                    # Individual embedding files
```

### Scripts
```
scripts/ai/
â”œâ”€â”€ compute_embeddings.py               # Feature extraction
â”œâ”€â”€ train_ranker.py                     # Ranking model training
â”œâ”€â”€ train_crop_proposer.py              # Crop model training
â”œâ”€â”€ test_anomaly_detection.py           # Model validation
â”œâ”€â”€ check_training_progress.py          # Training monitor
â””â”€â”€ (future) extract_historical_training.py
```

### Documentation
```
Documents/
â”œâ”€â”€ AI_PROJECT_IMPLEMENTATION_PLAN.md   # Master checklist (UPDATED)
â”œâ”€â”€ AI_HISTORICAL_DATA_EXTRACTION_PLAN.md
â”œâ”€â”€ AI_TRAINING_FROM_PAST_PROJECTS.md
â”œâ”€â”€ AI_TRAINING_PHASE2_QUICKSTART.md
â”œâ”€â”€ AUTOMATION_REVIEWER_SPEC.md
â””â”€â”€ AI_DOCUMENTS_INDEX.md
```

---

## ğŸ”„ Current Background Processes

**Training Process:**
- Command: `python scripts/ai/train_crop_proposer.py`
- Started: Oct 20, 2:47 PM
- Expected completion: ~3:00-3:05 PM
- Output: Check `nohup_crop.out` or process status

**Check Status:**
```bash
# Check if still running
ps aux | grep train_crop_proposer

# Check for output file
ls -lh data/ai_data/models/crop_proposer_v1*
```

---

## ğŸ§¹ Disk Space Cleanup

**Safe to Delete (After Crop Training Completes):**
- `sandbox/mojo2/` - 76 GB (embeddings already extracted)
- `sandbox/mojo2_challenge/` - 5.1 GB (experiment subset)
- `sandbox/mojo2_subset/` - 5.2 GB (experiment subset)

**Total Space to Reclaim:** ~86 GB

**Why Safe:**
- All embeddings cached in `data/ai_data/cache/`
- Mojo 2 original + final available for re-download if needed
- Training data extracted from logs, not raw images

---

## ğŸ’¡ Key Learnings

1. **High accuracy â‰  Good model:** 98% accuracy masked the fact that model just learned "pick stage 3"
2. **CLIP limitations:** Great for semantic understanding, poor for fine anatomical details
3. **Test for edge cases:** Anomaly detection test revealed the actual model behavior
4. **More data helps:** Historical projects will provide ~3x more training examples
5. **Embeddings are reusable:** Once extracted, can be used for multiple training runs

---

## ğŸ“‹ Recommended Prompt for New Chat

```
AI Training - Phase 2 Continuation

CONTEXT:
We're training AI models to automate image selection and cropping for my image processing workflow.

CURRENT STATUS:
âœ… Phase 2.2.1: Feature extraction complete (17,934 Mojo 2 embeddings)
âœ… Phase 2.3: Ranking model trained (97% accuracy, but only learned "pick highest stage" - needs improvement)
â³ Phase 2.4: Crop proposer training IN PROGRESS (7,194 examples, ~15 mins remaining)

NEXT STEPS:
1. Check if crop proposer training completed successfully
2. Download Mojo 1 (original + final) and extract training data
3. Extract embeddings from Mojo 1 images
4. Retrain both models on combined Mojo 1 + Mojo 2 data
5. Clean up sandbox/ to free disk space (~86 GB)

KEY FILES:
- Training logs: data/training/selection_only_log.csv, select_crop_log.csv
- Models: data/ai_data/models/ranker_v1.pt, crop_proposer_v1.pt
- Documentation: Documents/AI_PROJECT_IMPLEMENTATION_PLAN.md
- Embeddings cache: data/ai_data/cache/

IMPORTANT:
- Mojo 2 sandbox (76 GB) can be deleted after crop training completes
- Need to build script to extract training data from archived projects (original vs final comparison)
- Focus on getting models trained, then integrate into 01_ai_assisted_reviewer.py

What should we work on first?
```

---

**Session End:** October 20, 2025, ~2:55 PM  
**Duration:** ~2 hours  
**Status:** Phase 2.3 complete, Phase 2.4 in progress, ready for Mojo 1 work

