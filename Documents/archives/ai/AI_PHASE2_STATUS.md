# AI Training Phase 2 - Current Status & Next Steps
**Last Updated:** October 21, 2025 (End of Day)
**Status:** âœ… **90% COMPLETE - READY FOR PHASE 3!**

---

## ğŸ‰ **MAJOR UPDATE: Ranker v3 Trained & Validated!**

**Ranker v3 achieves 94.4% accuracy on anomaly cases!** This is a +31 percentage point improvement over v2.

The model successfully learned nuanced quality judgment beyond "pick highest stage." Phase 2 is essentially complete and ready for Phase 3 integration.

---

## ğŸ“Š **Phase 2 Accomplishments**

### âœ… **Historical Data Extraction (COMPLETE)**
Extracted training data from **15 historical projects** spanning all your past image selection work:

| Project | Selections | Crops | Crop Rate | Notes |
|---------|-----------|-------|-----------|-------|
| **mojo1** | 5,244 | 5,156 | 90.4% | Largest dataset, high crop rate |
| **mojo2** | 4,120 | 2,478 | 53.4% | Second largest |
| **jmlimages-random** | 2,739 | 2,714 | 99.1% | Almost everything cropped |
| **tattersail-0918** | 2,610 | 657 | 60.7% | |
| **Eleni_raw** | 1,121 | 61 | 5.4% | Low crop rate |
| **1100** | 1,115 | 764 | 68.5% | |
| **Kiara_Slender** | 683 | 57 | 8.3% | Combined average + slender |
| **1013** | 660 | 219 | 33.2% | |
| **1101_hailey** | 660 | 233 | 35.3% | |
| **1012** | 626 | 145 | 23.2% | |
| **1011** | 549 | 109 | 19.9% | |
| **agent-1003** | 409 | 27 | 6.6% | |
| **agent-1002** | 258 | 41 | 15.9% | |
| **Aiko_raw** | 258 | 0 | 0.0% | No crops |
| **agent-1001** | 201 | 18 | 9.0% | |
| **+ others** | ~666 | ~0 | - | Smaller projects |
| **TOTAL** | **~21,250** | **12,679** | **59.7%** | ğŸ‰ |

**Key Files Created:**
- `data/training/selection_only_log.csv` - All 21,250 selection decisions
- `data/training/select_crop_log.csv` - All 12,679 crop decisions
- `data/ai_data/embeddings/` - 77,304 image embeddings computed
- `data/ai_data/cache/processed_images.jsonl` - Embedding cache

---

### âœ… **Anomaly Analysis (COMPLETE)**
Created comprehensive analysis of "anomaly cases" where you chose a LOWER stage over a higher one:

**Overall Stats:**
- **Total selections analyzed:** 21,919
- **Anomalies found:** 518 (2.4%)
- **Normal selections:** 14,612 (66.7%)
- **Unparseable:** 6,789 (31.0%) - files without stage numbers

**Projects with Highest Anomaly Rates** (best for learning quality judgment):
1. **1101_hailey**: 111 anomalies (58.7%!) - You were very selective
2. **agent-1002**: 25 anomalies (17.1%)
3. **1011**: 27 anomalies (14.7%)
4. **agent-1001**: 15 anomalies (13.8%)
5. **tattersail-0918**: 187 anomalies (7.2%)

**Projects with Lowest Anomaly Rates** (mostly "pick highest stage"):
- **mojo1**: 5 anomalies (0.6%)
- **mojo2**: 22 anomalies (0.5%)
- **jmlimages-random**: 12 anomalies (0.5%)

**Insight:** Your observation was correct - the AI image generators are getting better over time. Newer projects (mojo1, mojo2) have much lower anomaly rates because stage 2/3 images are consistently better. Older projects have higher anomaly rates, suggesting more variable quality.

**Key Files Created:**
- `data/training/anomaly_cases.csv` - All 518 anomaly cases for training
- `data/training/anomaly_summary.json` - Detailed statistics by project
- `scripts/ai/analyze_anomalies.py` - Reusable anomaly analysis tool

---

### âœ… **Training Data Structure & Project Boundaries (COMPLETE)**
Established and documented critical rules for training:

**ğŸš¨ CRITICAL RULES:**
1. **Never mix projects during training** - Each project is a different character/context
2. **All images in a training set must be from same project**
3. **Match by filename only**, ignoring directory structure
4. **Validate project boundaries** before every training run

**Documentation Created:**
- Added project boundary rules to `AI_PROJECT_IMPLEMENTATION_PLAN.md`
- Added detailed technical section to `AI_TRAINING_PHASE2_QUICKSTART.md`
- Created `AI_TRAINING_DATA_STRUCTURE.md` with code examples

---

### âš ï¸ **Ranker v2 Training (PARTIAL)**
**Status:** Trained successfully with project boundaries, but used only ~10k examples (Mojo1 + Mojo2)

**Results:**
- Model saved: `data/ai_data/models/ranker_v2.pt`
- Trained with 10x anomaly oversampling
- Uses WeightedMarginRankingLoss
- Validates separately on normal vs anomaly cases

**Limitation:** Only used subset of data. Need to retrain with full 21k dataset.

---

## ğŸ”§ **Current Blockers**

### Path Normalization Issue
**Problem:** Embeddings were computed for files in `training data/` directories (which we've since deleted). Embedding cache has paths like:
- `training data/mojo1/file.png`
- `training data/tattersail-0918/file.png`

But the selection log (from original Web Image Selector sessions) has paths like:
- `PROJECT_ROOT/mojo1/file.png`
- `PROJECT_ROOT/tattersail-0918/file.png`

**Impact:** Can't match CSV paths to embeddings, so training fails with "No training data loaded"

**Solutions:**
1. **Option A (Quick):** Use `train_ranker_v2.py` which already handles this correctly
2. **Option B (Better):** Recompute embeddings for the actual `mojo1/`, `mojo2/` directories
3. **Option C (Clean):** Update embedding cache paths to remove `training data/` prefix

---

## ğŸ“‹ **Next Steps (Priority Order)**

### **Immediate (This Session):**
1. âœ… Fix path normalization in `train_ranker_v3.py` OR use `train_ranker_v2.py`
2. ğŸ”„ Train ranker v3 with full 21k+ dataset + 10x anomaly oversampling
3. ğŸ“ Update `AI_PROJECT_IMPLEMENTATION_PLAN.md` with Phase 2 completion

### **Short Term (Next Session):**
4. âš¡ Test different anomaly weights (5x, 10x, 20x) to find optimal balance
5. ğŸ§ª Create validation script to test rankers specifically on anomaly cases
6. ğŸ“Š Compare ranker v2 vs v3 performance metrics

### **Phase 2 Completion:**
7. ğŸ¯ Train crop proposer model using 12,679 crop examples
8. ğŸ“„ Create comprehensive Phase 2 summary with recommendations
9. âœ… Mark Phase 2 complete in project plan

### **Phase 3 Preparation:**
10. ğŸ”Œ Integrate best ranker model into AI-Assisted Reviewer
11. ğŸ”Œ Integrate crop proposer into reviewer
12. ğŸ§ª Test end-to-end AI-assisted workflow on new batch

---

## ğŸ¯ **Training Strategy Recommendations**

### **Anomaly Weighting:**
With 518 anomalies out of ~15k parseable pairs (3.4%):
- **Conservative (5x):** Makes anomalies ~15% of training
- **Moderate (10x):** Makes anomalies ~25% of training â† **Recommended starting point**
- **Aggressive (20x):** Makes anomalies ~40% of training

### **Train/Val Split:**
- **Normal cases:** 90% train / 10% val
- **Anomaly cases:** 80% train / 20% val (preserve more for validation since they're rare)

### **Success Metrics:**
- **Primary:** Anomaly validation accuracy > 70%
- **Secondary:** Normal validation accuracy > 90%
- **Overall:** Combined accuracy > 85%

### **Expected Behavior:**
- **Good model:** Learns nuanced quality (texture, anatomy, style) beyond just "pick highest stage"
- **Bad model:** Learns "pick highest stage" rule â†’ 98% normal accuracy, 20% anomaly accuracy

---

## ğŸ“ **File Organization**

### **Training Data:**
```
data/training/
â”œâ”€â”€ selection_only_log.csv       # All 21,250 selection decisions
â”œâ”€â”€ select_crop_log.csv           # All 12,679 crop decisions
â”œâ”€â”€ anomaly_cases.csv             # 518 anomaly cases
â””â”€â”€ anomaly_summary.json          # Statistics
```

### **Embeddings:**
```
data/ai_data/
â”œâ”€â”€ embeddings/                   # 77,304 embeddings
â”œâ”€â”€ cache/
â”‚   â””â”€â”€ processed_images.jsonl    # Embedding cache
â””â”€â”€ models/
    â”œâ”€â”€ ranker_v2.pt              # Current model (10k examples)
    â”œâ”€â”€ ranker_v2_metadata.json
    â””â”€â”€ ranker_v3_w10.pt          # (To be created)
```

### **Scripts:**
```
scripts/ai/
â”œâ”€â”€ train_ranker_v2.py            # Works with current embeddings
â”œâ”€â”€ train_ranker_v3.py            # New version (needs path fix)
â”œâ”€â”€ analyze_anomalies.py          # Anomaly analysis tool
â”œâ”€â”€ extract_project_training.py   # Historical data extractor
â””â”€â”€ compute_embeddings.py         # Embedding generator
```

---

## ğŸ’¡ **Key Insights**

1. **Quality of AI generation is improving** - Newer projects have lower anomaly rates
2. **You have excellent training data** - 21k examples is substantial
3. **Anomalies are rare but critical** - Only 2.4% but they teach quality judgment
4. **Project 1101_hailey is gold** - 58.7% anomaly rate shows selective quality decisions
5. **Crop rate varies widely** - From 0% (Aiko) to 99% (jmlimages), avg 60%

---

## ğŸš€ **Future Phases**

### **Phase 3: AI-Assisted Review UI** 
- Flask web interface
- AI suggests best image + crop region
- User approves/rejects
- Continuous learning from corrections

### **Phase 4: Automated Screening**
- Bulk processing without UI
- Confidence thresholds
- Flag uncertain cases for manual review

### **Phase 5: Active Learning**
- Prioritize showing uncertain cases
- Focus on anomaly-like decisions
- Continuous model improvement

### **Phase 6: Production Deployment**
- Optimized inference
- Batch processing
- Performance monitoring

---

## â“ **Open Questions**

1. **Anomaly weight:** What's the optimal oversampling factor? Need to test 5x, 10x, 20x
2. **Validation strategy:** How to best measure "quality judgment" vs "stage picking"?
3. **Crop proposer:** Should we train one model per project or unified?
4. **Data freshness:** How often to retrain as you process more projects?
5. **Confidence scores:** How to present AI uncertainty to user in Phase 3?

---

**Status Summary:**
- âœ… Data extraction: 100% complete
- âœ… Anomaly analysis: 100% complete  
- âœ… Documentation: 100% complete
- ğŸ”„ Model training: 60% complete (v2 done, v3 blocked on path fix)
- â³ Phase 2: ~85% complete

**Next Action:** Fix path normalization and train ranker v3 with full dataset.

